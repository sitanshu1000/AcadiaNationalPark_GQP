{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'proof of concept example for deep neural network NB regression\\nParts of the code are from Goekcen Eraslan\\nhttps://github.com/gokceneraslan/autoencoder\\npython 3 requirements:\\n----------------------\\nnumpy\\ntensorflow>=1.0.0\\nkeras>=2.0.0\\nmatplotlib\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"proof of concept example for deep neural network NB regression\n",
    "Parts of the code are from Goekcen Eraslan\n",
    "https://github.com/gokceneraslan/autoencoder\n",
    "python 3 requirements:\n",
    "----------------------\n",
    "numpy\n",
    "tensorflow>=1.0.0\n",
    "keras>=2.0.0\n",
    "matplotlib\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class SliceLayer(Layer):\n",
    "    def __init__(self, index, **kwargs):\n",
    "        self.index = index\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('Input should be a list')\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x[self.index]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[self.index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class NB(object):\n",
    "    def __init__(self, theta=None, scope='nbinom_loss/',\n",
    "                 scale_factor=1.0, debug=False):\n",
    "\n",
    "        # for numerical stability\n",
    "        self.eps = 1e-10\n",
    "        self.scale_factor = scale_factor\n",
    "        self.debug = debug\n",
    "        self.scope = scope\n",
    "        self.theta = theta\n",
    "\n",
    "    def loss(self, y_true, y_pred, reduce=True):\n",
    "        scale_factor = self.scale_factor\n",
    "        eps = self.eps\n",
    "\n",
    "        with tf.name_scope(self.scope):\n",
    "            y_true = tf.cast(y_true, tf.float32)\n",
    "            y_pred = tf.cast(y_pred, tf.float32) * scale_factor\n",
    "\n",
    "            # Clip theta\n",
    "            theta = tf.minimum(self.theta, 1e6)\n",
    "\n",
    "            t1 = -tf.math.lgamma(y_true+theta+eps)\n",
    "            t2 = tf.math.lgamma(theta+eps)\n",
    "            t3 = tf.math.lgamma(y_true+1.0)\n",
    "            t4 = -(theta * (tf.math.log(theta+eps)))\n",
    "            t5 = -(y_true * (tf.math.log(y_pred+eps)))\n",
    "            t6 = (theta+y_true) * tf.math.log(theta+y_pred+eps)\n",
    "\n",
    "            final = t1 + t2 + t3 + t4 + t5 + t6\n",
    "\n",
    "            if reduce:\n",
    "                final = tf.reduce_mean(final)\n",
    "\n",
    "        return final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def build_poisson_model(input_shape):\n",
    "    inputs = Input(\n",
    "        shape=(input_shape[-1],), name='main_input'\n",
    "    )\n",
    "\n",
    "    x = Dense(10)(inputs)\n",
    "    l = Dense(1, activation=K.exp)(x)\n",
    "    model = Model(inputs=inputs, outputs=l)\n",
    "    model.compile(\n",
    "        loss=\"poisson\",\n",
    "        optimizer=\"adam\"\n",
    "    )\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def build_nb_model(input_shape):\n",
    "    inputs = Input(\n",
    "        shape=(input_shape[-1],), name='main_input'\n",
    "    )\n",
    "\n",
    "    x = Dense(10)(inputs)\n",
    "    m = Dense(1, activation=K.exp)(x)\n",
    "    d = Dense(1, activation=lambda x: 1.0/(K.exp(x)+1e-10))(x)\n",
    "    outputs = SliceLayer(index=0, name='slice')([m, d])\n",
    "    nb = NB(d)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    beta_model = Model(inputs=inputs, outputs=d)\n",
    "    model.compile(\n",
    "        loss=nb.loss,\n",
    "        optimizer=\"adam\"\n",
    "    )\n",
    "    return model, beta_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_data(nb_classes, nb_features, nb_samples_per_class):\n",
    "    X = []\n",
    "    y = []\n",
    "    for cl in range(1, nb_classes + 1):\n",
    "        for i in range(nb_samples_per_class):\n",
    "            desired_elements = [1.0] * cl\n",
    "            undesired_elements = (np.random.random_sample(\n",
    "                (nb_features - cl)\n",
    "            ) * 0.1).tolist()\n",
    "            ll = desired_elements + undesired_elements\n",
    "            ll = np.array(ll)\n",
    "            X.append(ll)\n",
    "            y.append(cl)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 10) type: float64\n",
      "y shape: (5000,) type: int64\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 1ms/step - loss: -2.2225\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: -4.6191\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: -4.6495\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: -4.6688\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: -4.6804\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: -4.6877\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: -4.6924\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: -4.6956\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: -4.6978\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: -4.6995\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/98s1yvbs2zq9h146qcbc3t_h0000gn/T/ipykernel_74873/1682128123.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_pred_poisson = np.floor(l).astype(np.int)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 239, in __call__\n        self._loss_metric.update_state(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/metrics.py\", line 455, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 254, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_4'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/90/98s1yvbs2zq9h146qcbc3t_h0000gn/T/ipykernel_74873/1682128123.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0;31m# fit negative binomial model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m     nb_model.fit(\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnb_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: in user code:\n\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 239, in __call__\n        self._loss_metric.update_state(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/metrics.py\", line 455, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/Library/anaconda3/envs/ds_env/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 254, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_4'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "    maxcount = 10\n",
    "    nb_samples = 500\n",
    "    nb_features = 10\n",
    "    nb_epochs = 10\n",
    "\n",
    "    X_train, y_train = generate_data(\n",
    "        maxcount,\n",
    "        nb_features,\n",
    "        nb_samples,\n",
    "    )\n",
    "\n",
    "    X_test, y_test = generate_data(\n",
    "        maxcount,\n",
    "        nb_features,\n",
    "        100,\n",
    "    )\n",
    "    print('X shape:', X_train.shape, 'type:', X_train.dtype)\n",
    "    print('y shape:', y_train.shape, 'type:', y_train.dtype)\n",
    "\n",
    "    # build poisson model\n",
    "    p_model = build_poisson_model(X_train.shape)\n",
    "\n",
    "    # fit poisson model\n",
    "    p_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=nb_epochs,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # infer mean\n",
    "    l = p_model.predict(X_test)\n",
    "    # count inferene\n",
    "    y_pred_poisson = np.floor(l).astype(np.int)\n",
    "\n",
    "    # build nb model\n",
    "    nb_model, beta_model = build_nb_model(X_train.shape)\n",
    "\n",
    "    # fit negative binomial model\n",
    "    nb_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=nb_epochs,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # predict mean\n",
    "    m = nb_model.predict(\n",
    "        X_test,\n",
    "    )\n",
    "    # predict dispersion\n",
    "    d = beta_model.predict(X_test)\n",
    "\n",
    "    # count inference\n",
    "    y_pred_nb = np.floor(m*((d-1)/d)).astype(np.int)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    ind = np.arange(y_test.shape[0])\n",
    "    ax1.pcolormesh(X_test.T)\n",
    "    ax1.set_xlabel('Input')\n",
    "    ax2.plot(ind, y_pred_poisson, c='b', alpha=0.7, label='Poisson Count')\n",
    "    ax2.plot(l, c='m', label='$\\lambda$')\n",
    "    # ax2.plot(ind, y_pred_nb, c='r', alpha=0.7, label='NB')\n",
    "    ax2.plot(ind, y_test, c='g', label='Ground Truth')\n",
    "    ax2.set_xlabel('Output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}